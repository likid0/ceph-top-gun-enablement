=  Ceph Storage Rados Gateway Server Side Encryption Configuration

== Introduction

The Ceph Object Gateway supports server-side encryption of uploaded objects, with 3 options for the management of encryption keys. Server-side encryption means that the data is sent over HTTP in its unencrypted form, and the Ceph Object Gateway stores that data in the Ceph Storage Cluster in encrypted form.


Three types of Server side Encryption are available:

- *CUSTOMER-PROVIDED KEYS(SSE-C)*

In this mode, the client passes an encryption key along with each request to read or write encrypted data. It is the clientâ€™s responsibility to manage those keys and remember which key was used to encrypt each object.
This is implemented in S3 according to the Amazon SSE-C specification.

As all key management is handled by the client, no special Ceph configuration is needed to support this encryption mode.

- *KEY MANAGEMENT SERVICE(SSE-KMS)*

In this mode, an administrator stores keys in a secure key management service. These keys are then retrieved on demand by the Ceph Object Gateway to serve requests to encrypt or decrypt data.
This is implemented in S3 according to the Amazon SSE-KMS specification.

In principle, any key management service could be used here. Currently integration with Barbican, Vault, and KMIP are implemented.

- *SSE-S3* This option is not supported downstream

This makes key management invisible to the user. They are still stored in vault, but they are automatically created and deleted by Ceph. and retrieved as required to serve requests to encrypt or decrypt data.
This is implemented in S3 according to the Amazon SSE-S3 specification.

In principle, any key management service could be used here. Currently only integration with Vault, is implemented.


== SSE-KMS RGW introduction


Assuming, one cannot encrypt the devices use by Ceph Storage and exposed by Rados Gateway (RGW) through S3 protocol, one can ensure that data is encrypted in transit and at rest by using SSL for accessing the RGW S3 endpoint as well as requesting Server Side Encryption with Key management (sse-kms) on the bucket level.

Encrypting data in a bucket will not have an impact on the Client accessing the data through the RGW S3 endpoint (so no need to change your code) but will prevent someone else to retrieve the payload from the disk back end.

Additional Software used for this lab:

- HashiCorp Vault 

[NOTE]
====
The lab to will guide you through the simplest way to get aws:kms configured
for one or many buckets but the utilized configuration shall not be used for
Production environments as the token based authentication has obvious
disadvantages over an Agent based deployment and is not suported downstream. Furthermore, this example uses the Vault root token to simplify setup and necessary steps which is not best practices.
====

[NOTE]
====
Even though this lab is not focused on Production Environments, ensure to have all keys/tokens generated stored somewhere safe as loosing only one of them will end in data loss due to not being able to decrypt the data anymore

== Setting up HashiCorp Vault

The requirements for Ceph of podman and containers shall be used for HashiCorp
Vault as well. We will run thei Vault instance from server
`workstation.example.com`. Persistent Storage will be served from the Host ephemeral storage.

----
# podman login registry.connect.redhat.com
# podman run -d -ti -p 8200:8200  --rm --name vault -e SKIP_SETCAP=true -e VAULT_DISABLE_MLOCK=true -v vault:/vault/file registry.connect.redhat.com/hashicorp/vault:1.9.10-ubi
# podman logs 44cad1840217 | grep -E '(Unseal|Root)'
Unseal Key: ffFk1kdOK5Gq9C3IKUWI+M=
Root Token: s.FIeY8vKFdAzxn
# podman exec -ti vault /bin/sh
$ export VAULT_ADDR=http://127.0.0.1:8200
$ export VAULT_TOKEN=s.FIeYz7vkiNfgNSt8vKFdAzxn
$ vault operator unseal  ffFk1kaHZbFa4dfqc0MvZx/yV+JdOK5Gq9C3IKUWI+M=
Key             Value
---             -----
Seal Type       shamir
Initialized     true
Sealed          false
Total Shares    1
Threshold       1
Version         1.9.10
Storage Type    inmem
Cluster Name    vault-cluster-b6302d4c
Cluster ID      2f9ab7a7-3fbd-c661-691a-308cfd508f71
HA Enabled      false
sh-4.4$ vault secrets enable -version=2 kv
Success! Enabled the kv secrets engine at: kv/
sh-4.4$ vault kv put secret/encrypted-bucket-key key=$(openssl rand -base64 32)
Key                Value
---                -----
created_time       2023-01-03T17:55:40.306272723Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1
sh-4.4$ vault kv get secret/encrypted-bucket-key
======= Metadata =======
Key                Value
---                -----
created_time       2023-01-03T17:55:40.306272723Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1

=== Data ===
Key    Value
---    -----
key    J4wGGNEen6gOxHRvGhOFhyEnqwCoLBhiUb4lK6GThCE=

[root@ceph-node01 ~]# export FSID=$(cephadm shell ceph config get mon fsid)
Inferring fsid c7878d3c-8ab3-11ed-b9f6-2cc26078e4ef
Using recent ceph image registry.redhat.io/rhceph/rhceph-5-rhel8@sha256:31fbe18b6f81c53d21053a4a0897bc3875e8ee8ec424393e4d5c3c3afd388274
[root@ceph-node01 ~]# echo 's.FIeYz7vkiNfgNSt8vKFdAzxn' > /var/run/ceph/${FSID}/.rgw-vault-token
[root@ceph-node01 ~]# chmod 0400  /var/run/ceph/${FSID}/.rgw-vault-token && chown ceph:ceph  /var/run/ceph/${FSID}/.rgw-vault-token
[root@ceph-node01 ~]#
[root@ceph-node01 ~]# ceph config-key set config/client.rgw/rgw_crypt_vault_addr http://workstation.example.com:8200
set config/client.rgw/rgw_crypt_vault_addr
[root@ceph-node01 ~]# ceph config-key set config/client.rgw/rgw_crypt_vault_auth token
set config/client.rgw/rgw_crypt_vault_auth
[root@ceph-node01 ~]# ceph config-key set config/client.rgw/rgw_crypt_vault_secret_engine kv
set config/client.rgw/rgw_crypt_vault_secret_engine
[root@ceph-node01 ~]# ceph config-key set config/client.rgw/rgw_crypt_vault_token_file /var/run/ceph/.rgw-vault-token
set config/client.rgw/rgw_crypt_vault_token_file
[root@ceph-node01 ~]# ceph config-key set config/client.rgw/rgw_crypt_vault_prefix /v1/secret/data
set config/client.rgw/rgw_crypt_vault_prefix
[root@ceph-node01 ~]# ceph orch restart rgw.objectgw
Scheduled to restart rgw.objectgw.ceph-node02.lezmwh on host 'ceph-node02'

----



