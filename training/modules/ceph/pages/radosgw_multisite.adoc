== RadosGW Multisite

=== Introduction

A single zone configuration typically consists of one zone group containing one zone and one or more ceph-radosgw instances where you may load-balance gateway client requests between the instances. In a single zone configuration, typically multiple gateway instances point to a single Ceph storage cluster.

image::multisite-intro.png[Multisite Diagram]

Ceph by its own design is synchronous. And so that means from a client's level, write is not acknowledged until all replication copies are written into the cluster. So, for example, if you have a two-way replication cluster with your failure domain at the host level, and your client writes into the cluster, that client does not receive acknowledgment until that second copy has been written to any other node than where the primary write happened. So, you can very quickly see where this would become unusable at the multisite level, especially when the cluster spanned vast geographic distances to one another.

This is where asynchronous replication is used. This allows each cluster in the multisite to become eventually consistent with each other.

So, from the top down, we have realm, Zone Group and zones and I'm going to explain all those right now. So, a realm represents a globally unique namespace and represents the highest level of the Ceph multisite cluster. Each realm can then contain either one or multiple zone groups and multiple zones. So next we have zone groups. These used to be called regions and they're essentially made to define one or more multiple geographic areas. So next we have zones. These are the lowest level of the Ceph multisite configuration and they're represented by one or more object gateways underneath one single Ceph cluster.

=== RGW Multisite components

. zone
- Defines a logical group consisting of one or more Ceph Object Gateway instances
- Configuring zones differs from typical Ceph configuration procedures, because not all of the settings end up in a Ceph configuration file
- There will be one zone that should be designated as the Master zone in a zonegroup
- The Master zone will handle all bucket and user creation
- Secondary zone can receive bucket and user operations, but will redirect them to the Master zone
- If the Master zone is down, bucket and user operations will fail
- It is possible to promote a secondary zone to Master zone

NOTE: This a complex operation. It is recommended only when the Master zone will be down for a long period of time

. zone group
A zone group is a set of one or more zones. Data stored in one zone in the zone group is
replicated to all other zones in the zone group. One zone in every zone group is designated as
the master zone for that group. The other zones in the zone group are secondary zones.

. realm
A realm represents the global namespace for all objects and buckets in the multisite
replication space. A realm contains one or more zone groups, each of which contains one
or more zones. One zone group in the realm is designated as the master zone group, and
the others are secondary zone groups. All RADOS Gateways in the environment pull their
configuration from the RADOS Gateway in the master zone group and master zone.
Because the master zone in the master zone group handles all metadata updates, operations such
as creating users must occur in the master zone.


. Multi-zone: A more advanced configuration consists of one zone group and multiple zones, each zone with one or more ceph-radosgw instances. Each zone is backed by its own Ceph Storage Cluster. Multiple zones in a zone group provides disaster recovery for the zone group should one of the zones experience a significant failure. In Kraken, each zone is active and may receive write operations. In addition to disaster recovery, multiple active zones may also serve as a foundation for content delivery networks.
. Multi-zone-group: Formerly called ‘regions’, Ceph Object Gateway can also support multiple zone groups, each zone group with one or more zones. Objects stored to zones in one zone group within the same realm as another zone group will share a global object namespace, ensuring unique object IDs across zone groups and zones.
. Multiple Realms: In Kraken, the Ceph Object Gateway supports the notion of realms, which can be a single zone group or multiple zone groups and a globally unique namespace for the realm. Multiple realms provide the ability to support numerous configurations and namespaces.


=== Multisite Lab.

In this lab we are going to deploy an advanced configuration that consists
of a single realm with one zone group and two zones, each zone with two Ceph RGW instances. Each
zone is backed by its own Ceph Storage Cluster. Multiple zones in a zone group
provides disaster recovery for the zone group should one of the zones
experience a significant failure. Each zone is active and may receive write
operations.

=== Configure the Master Realm, Zonegroup and Zone.

[TIP]
====
If you have already completed the RadosGW introduction module you can jump
this section, and continue with section `Configure the Secondary Zone`
====

[WARNING]
====
Run commands on the master/primary cluster.
====

. Create a realm:

+
[source,sh]
----
# radosgw-admin realm create --rgw-realm=multisite --default
{
    "id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "name": "multisite",
    "current_period": "0ad144e7-a880-43ab-8a64-c9deaf581280",
    "epoch": 1
}
----

. Create a zone group:
+
[source,sh]
----
# radosgw-admin zonegroup create --rgw-zonegroup=multisite_zonegroup --endpoints=http://proxy01:8000 --master --default
{
    "id": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
    "name": "multisite_zonegroup",
    "api_name": "multisite_zonegroup",
    "is_master": "true",
    "endpoints": [],
    "hostnames": [],
    "hostnames_s3website": [],
    "master_zone": "",
    "zones": [],
    "placement_targets": [],
    "default_placement": "",
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "sync_policy": {
        "groups": []
    }
}
----
. Create a zone:
+
[source,sh]
----
# radosgw-admin zone create --rgw-zonegroup=multisite_zonegroup --rgw-zone=zone1 --access-key=sync --secret=sync --master --default --endpoints=http://proxy01:8000
{
    "id": "0e06b95f-3b6e-4a1c-95e8-b857f699e9e3",
    "name": "zone1",
    "domain_root": "zone1.rgw.meta:root",
    "control_pool": "zone1.rgw.control",
    "gc_pool": "zone1.rgw.log:gc",
    "lc_pool": "zone1.rgw.log:lc",
    "log_pool": "zone1.rgw.log",
    "intent_log_pool": "zone1.rgw.log:intent",
    "usage_log_pool": "zone1.rgw.log:usage",
    "roles_pool": "zone1.rgw.meta:roles",
    "reshard_pool": "zone1.rgw.log:reshard",
    "user_keys_pool": "zone1.rgw.meta:users.keys",
    "user_email_pool": "zone1.rgw.meta:users.email",
    "user_swift_pool": "zone1.rgw.meta:users.swift",
    "user_uid_pool": "zone1.rgw.meta:users.uid",
    "otp_pool": "zone1.rgw.otp",
    "system_key": {
        "access_key": "sync",
        "secret_key": "sync"
    },
    "placement_pools": [
        {
            "key": "default-placement",
            "val": {
                "index_pool": "zone1.rgw.buckets.index",
                "storage_classes": {
                    "STANDARD": {
                        "data_pool": "zone1.rgw.buckets.data"
                    }
                },
                "data_extra_pool": "zone1.rgw.buckets.non-ec",
                "index_type": 0
            }
        }
    ],
    "realm_id": "b3f73708-67c5-4b19-b378-6af9cc66c0b0",
    "notif_pool": "zone1.rgw.log:notif"
}
----

[TIP]
====
We can have one or mode REALMS,ZONEGROUPS or ZONES, if we don't specifiy
them on the radosgw-admin command with --rgw-realm , --rgw-zonegroup= ,
--rgw-zone= , the radosgw-admin command will use the ones set as the defaul
using the --default flag like we did in the previous commands.
====

. Commit the changes:
+
[source,sh]
----
[ceph: root@ceph-mon01 /]# radosgw-admin period update --rgw-realm=multisite --commit
----

. Deploy the RGW daemons with the name `multi.zone1`:
+
[source,sh]
----
[ceph: root@ceph-mon01 /]# ceph orch apply rgw multi.zone1 --realm=multisite --zone=zone1 --placement="2 proxy01 ceph-node02" --port=8000
----
+
[source,texinfo]
----
Scheduled multi.zone1 update...
# ceph orch ps | grep rgw
rgw.multi.zone1.ceph-node02.lviwfb  ceph-node02  *:8000       running (3m)      3m ago   3m    45.7M        -  16.2.8-85.el8cp  b2c997ff1898  0e3521f3a162
rgw.multi.zone1.proxy01.mhawfj      proxy01      *:8000       running (30m)     4m ago  30m    61.9M        -  16.2.8-85.el8cp  b2c997ff1898  4de70934f04e
----

=== Create Sync User

Create a system user that we will use to configure the sync between sites.

----
# radosgw-admin user create --uid=syncuser --display-name="syncuser" --access-key=sync --secret=sync --system
----

=== Configure Seconday Zone

Steps to configure the RADOS Gateway instance on the secondary zone.

[WARNING]
====
Run commands on the seconday Ceph cluster
====

----
# radosgw-admin realm pull --rgw-realm=multisite  --url=http://proxy01:8000 --access-key=sync --secret=sync --default
2022-12-23T09:26:56.377-0500 7fccf8715500  1 error read_lastest_epoch .rgw.root:periods.e7ccb8e8-4a93-4a87-9a6d-8a650696e839.latest_epoch
2022-12-23T09:26:56.415-0500 7fccf8715500  1 Set the period's master zonegroup 6b9fbc87-3202-4a35-85d0-e3e16fc91b32 as the default
{
    "id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
    "name": "multisite",
    "current_period": "e7ccb8e8-4a93-4a87-9a6d-8a650696e839",
    "epoch": 2
}
----


Pull the period.
----
# radosgw-admin period pull --url=http://proxy01:8000 --access-key=sync --secret=sync
{
    "id": "e7ccb8e8-4a93-4a87-9a6d-8a650696e839",
    "epoch": 5,
    "predecessor_uuid": "68a74587-6404-4798-83e0-6cd3bf417288",
    "sync_status": [],
    "period_map": {
        "id": "e7ccb8e8-4a93-4a87-9a6d-8a650696e839",
        "zonegroups": [
            {
                "id": "6b9fbc87-3202-4a35-85d0-e3e16fc91b32",
                "name": "multisite_zonegroup",
                "api_name": "multisite_zonegroup",
                "is_master": "true",
                "endpoints": [],
                "hostnames": [],
                "hostnames_s3website": [],
                "master_zone": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                "zones": [
                    {
                        "id": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                        "name": "zone1",
                        "endpoints": [],
                        "log_meta": "false",
                        "log_data": "false",
                        "bucket_index_max_shards": 11,
                        "read_only": "false",
                        "tier_type": "",
                        "sync_from_all": "true",
                        "sync_from": [],
                        "redirect_zone": ""
                    }
                ],
                "placement_targets": [
                    {
                        "name": "default-placement",
                        "tags": [],
                        "storage_classes": [
                            "SSD",
                            "STANDARD"
                        ]
                    },
                    {
                        "name": "ssd",
                        "tags": [
                            "allowed-ssd"
                        ],
                        "storage_classes": [
                            "STANDARD"
                        ]
                    }
                ],
                "default_placement": "default-placement",
                "realm_id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
                "sync_policy": {
                    "groups": []
                }
            }
        ],
        "short_zone_ids": [
            {
                "key": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                "val": 2695141038
            }
        ]
    },
    "master_zonegroup": "6b9fbc87-3202-4a35-85d0-e3e16fc91b32",
    "master_zone": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
    "period_config": {
        "bucket_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        },
        "user_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        }
    },
    "realm_id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
    "realm_name": "multisite",
    "realm_epoch": 2
}
----

Create a secondary zone.

----
# radosgw-admin zone create --rgw-zone=zone2 --rgw-zonegroup=multisite_zonegroup --endpoints=http://proxy02:8000 --access-key=sync --secret=sync --default
2022-12-23T09:28:04.140-0500 7f905d907500  0 failed reading obj info from .rgw.root:zone_info.c5dc9503-6c11-4851-91bd-f1d5ca61473c: (2) No such file or directory
2022-12-23T09:28:04.140-0500 7f905d907500  0 WARNING: could not read zone params for zone id=c5dc9503-6c11-4851-91bd-f1d5ca61473c name=zone1
{
    "id": "5c14f28b-72f2-4323-aa35-24bd1cb8fc0e",
    "name": "zone2",
    "domain_root": "zone2.rgw.meta:root",
    "control_pool": "zone2.rgw.control",
    "gc_pool": "zone2.rgw.log:gc",
    "lc_pool": "zone2.rgw.log:lc",
    "log_pool": "zone2.rgw.log",
    "intent_log_pool": "zone2.rgw.log:intent",
    "usage_log_pool": "zone2.rgw.log:usage",
    "roles_pool": "zone2.rgw.meta:roles",
    "reshard_pool": "zone2.rgw.log:reshard",
    "user_keys_pool": "zone2.rgw.meta:users.keys",
    "user_email_pool": "zone2.rgw.meta:users.email",
    "user_swift_pool": "zone2.rgw.meta:users.swift",
    "user_uid_pool": "zone2.rgw.meta:users.uid",
    "otp_pool": "zone2.rgw.otp",
    "system_key": {
        "access_key": "sync",
        "secret_key": "sync"
    },
    "placement_pools": [
        {
            "key": "default-placement",
            "val": {
                "index_pool": "zone2.rgw.buckets.index",
                "storage_classes": {
                    "STANDARD": {
                        "data_pool": "zone2.rgw.buckets.data"
                    }
                },
                "data_extra_pool": "zone2.rgw.buckets.non-ec",
                "index_type": 0
            }
        }
    ],
    "realm_id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
    "notif_pool": "zone2.rgw.log:notif"
}
----

Commit the changes.

----
# radosgw-admin period update --commit
Sending period to new master zone c5dc9503-6c11-4851-91bd-f1d5ca61473c
{
    "id": "e7ccb8e8-4a93-4a87-9a6d-8a650696e839",
    "epoch": 7,
    "predecessor_uuid": "68a74587-6404-4798-83e0-6cd3bf417288",
    "sync_status": [],
    "period_map": {
        "id": "e7ccb8e8-4a93-4a87-9a6d-8a650696e839",
        "zonegroups": [
            {
                "id": "6b9fbc87-3202-4a35-85d0-e3e16fc91b32",
                "name": "multisite_zonegroup",
                "api_name": "multisite_zonegroup",
                "is_master": "true",
                "endpoints": [
                    "http://proxy01:8000"
                ],
                "hostnames": [],
                "hostnames_s3website": [],
                "master_zone": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                "zones": [
                    {
                        "id": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                        "name": "zone1",
                        "endpoints": [
                            "http://proxy01:8000"
                        ],
                        "log_meta": "false",
                        "log_data": "true",
                        "bucket_index_max_shards": 11,
                        "read_only": "false",
                        "tier_type": "",
                        "sync_from_all": "true",
                        "sync_from": [],
                        "redirect_zone": ""
                    },
                    {
                        "id": "ec5a7187-95e1-4bf2-8519-208175c81487",
                        "name": "zone2",
                        "endpoints": [
                            "http://proxy02:8000"
                        ],
                        "log_meta": "false",
                        "log_data": "true",
                        "bucket_index_max_shards": 11,
                        "read_only": "false",
                        "tier_type": "",
                        "sync_from_all": "true",
                        "sync_from": [],
                        "redirect_zone": ""
                    }
                ],
                "placement_targets": [
                    {
                        "name": "default-placement",
                        "tags": [],
                        "storage_classes": [
                            "SSD",
                            "STANDARD"
                        ]
                    },
                    {
                        "name": "ssd",
                        "tags": [
                            "allowed-ssd"
                        ],
                        "storage_classes": [
                            "STANDARD"
                        ]
                    }
                ],
                "default_placement": "default-placement",
                "realm_id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
                "sync_policy": {
                    "groups": []
                }
            }
        ],
        "short_zone_ids": [
            {
                "key": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
                "val": 2695141038
            },
            {
                "key": "ec5a7187-95e1-4bf2-8519-208175c81487",
                "val": 3374434257
            }
        ]
    },
    "master_zonegroup": "6b9fbc87-3202-4a35-85d0-e3e16fc91b32",
    "master_zone": "c5dc9503-6c11-4851-91bd-f1d5ca61473c",
    "period_config": {
        "bucket_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        },
        "user_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        }
    },
    "realm_id": "e72107cb-4b3f-49b9-abb0-83c68a9967f9",
    "realm_name": "multisite",
    "realm_epoch": 2
}
----

Create the RADOS Gateway service for the secondary zone.

----
# ceph orch apply rgw multi.zone2 --realm=multisite --zone=zone2 --placement="2 proxy02 ceph-mon02" --port=8000
----

Use the radosgw-admin sync status command, we can see the sync is started and a
full copy of the master zone is being synced with the secondary zone

----
# radosgw-admin sync status
          realm e72107cb-4b3f-49b9-abb0-83c68a9967f9 (multisite)
      zonegroup 6b9fbc87-3202-4a35-85d0-e3e16fc91b32 (multisite_zonegroup)
           zone ec5a7187-95e1-4bf2-8519-208175c81487 (zone2)
   current time 2022-12-23T14:41:08Z
  metadata sync syncing
                full sync: 1/64 shards
                full sync: 21 entries to sync
                incremental sync: 63/64 shards
                metadata is behind on 1 shards
                behind shards: [0]
      data sync source: c5dc9503-6c11-4851-91bd-f1d5ca61473c (zone1)
                        syncing
                        full sync: 63/128 shards
                        full sync: 77 buckets to sync
                        incremental sync: 65/128 shards
                        data is behind on 63 shards
                        behind shards: [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,36,37,38,39,40,41,42,43,44,45,46,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,105,106,107,108,109,110,111,112,113,114,115,116]
----

[TIP]
====
The output can differ depending on the sync status. The shards are described as two different types during sync:
- Behind shards are shards that need a full data sync and shards needing an incremental data sync because they are not up-to-date.
- Recovery shards are shards that encountered an error during sync and marked for retry. The error mostly occurs on minor issues like acquiring a lock on a bucket. This will typically resolve itself.
====


After a while if we run the same command we will probably see metadata and data in sync:

----
# radosgw-admin sync status
          realm 4818713d-4bdf-4ef7-ab7b-c9ceb8009bdb (multisite)
      zonegroup ce0533e9-ebe7-45f4-8126-91e9f9253599 (multisite_zonegroup)
           zone d0492b20-abca-463a-8972-9eae824537fd (zone2)
   current time 2022-12-24T10:52:29Z
  metadata sync syncing
                full sync: 0/64 shards
                incremental sync: 64/64 shards
                metadata is caught up with master
      data sync source: 4913e13d-17a9-4c6f-96a4-91b87d2cfe68 (zone1)
                        syncing
                        full sync: 0/128 shards
                        incremental sync: 128/128 shards
                        data is caught up with source
----

With this current configuration every data object will be synced
bi-directionally on both sites, so we can upload objects to site1 or
site2(Active/Active) and they 
we will get replicated in async mode between sites, using the terme eventually
consistent.

[WARNING]
====
Remember that metadata changes should only be done on the master node,
the master node will take care of replicating the metadata changes to the rest
of the zones in the zonegroup
====

[TIP]
====
By default, the objects are not verified again after the synchronization of an object was successful. To enable that, you can set rgw_sync_obj_etag_verify to true. After enabling the optional objects that will be synchronized going forward, an additional MD5 checksum will verify that it is computed on the source and the destination. This is to ensure the integrity of the objects fetched from a remote server over HTTP including multisite sync. This option can decrease the performance of your RGW as more computation is needed.
====

We can see the sync direction configuration using `radosgw-admin sync info`
command, we can see than sources and destinations are replicating `*` all
buckets and their data between sites.

----
# radosgw-admin sync info
{
    "sources": [
        {
            "id": "all",
            "source": {
                "zone": "zone1",
                "bucket": "*"
            },
            "dest": {
                "zone": "zone2",
                "bucket": "*"
            },
            "params": {
                "source": {
                    "filter": {
                        "tags": []
                    }
                },
                "dest": {},
                "priority": 0,
                "mode": "system",
                "user": ""
            }
        }
    ],
    "dests": [
        {
            "id": "all",
            "source": {
                "zone": "zone2",
                "bucket": "*"
            },
            "dest": {
                "zone": "zone1",
                "bucket": "*"
            },
            "params": {
                "source": {
                    "filter": {
                        "tags": []
                    }
                },
                "dest": {},
                "priority": 0,
                "mode": "system",
                "user": ""
            }
        }
    ],
----

For multi-site only, you can check out the metadata log (mdlog), the bucket index log (bilog) and the data log (datalog). You can list them and also trim them which is not needed in most cases as rgw_sync_log_trim_interval is set to 20 minutes as default. You shouldn’t have to trim it at any time as it could cause side effects otherwise.


