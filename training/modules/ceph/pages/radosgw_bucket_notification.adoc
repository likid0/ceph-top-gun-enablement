= RGW Bucket Notifications

== Introduction

Ceph is a suitable SDS solution for Big Data and Machine Learning/AI data scale. One of the new features, “Bucket Notifications”, provides Amazon SNS-SQS relationship between RGW and MQ targets and provides the ability of getting a notification each time an object is created/removed. In that way, we could define a topic in which RGW will send notifications to (AKA SNS topic), and a queue waiting for notifications to come (AKA SQS). The supported target endpoints are RabbitMQ (AMQP), Kafka, and HTTP.

A user can create topics. A topic entity is defined by its name and is “per tenant”. A user can associate its topics (via notification configuration) only with buckets it owns.

A notification entity must be created in order to send event notifications for a specific bucket. A notification entity can be created either for a subset of event types or for all event types (which is the default). The notification may also filter out events based on matches of the prefixes and suffixes of (1) the keys, (2) the metadata attributes attached to the object, or (3) the object tags.

NOTE: To enable bucket notifications API, the rgw_enable_apis configuration parameter should contain: 'notifications'.

== Lab. Configure Bucket Notifications with Kafka

Our `workstation` server is running a single node kafka instance that we can use
for this lab. Let's check that the kafka services are runing on the
`workstation` node

----
# systemctl status kafka.service
# systemctl status zookeeper.service
----

It's listnening on that standard broker port '9092'

----
 netstat -natlop | grep 9092
tcp6       0      0 :::9092                 :::*                    LISTEN      37321/java           off (0.00/0/0)
----

Let's create a topic called `storage` where RGW will send the notifications

----
# /opt/kafka/bin/kafka-topics.sh --create --bootstrap-server workstation:9092 --topic storage
# /opt/kafka/bin/kafka-topics.sh --describe --bootstrap-server workstation:9092  --topic storage
Topic: storage	TopicId: k1FR5KvXQDm3AuF1sHKkIA	PartitionCount: 1	ReplicationFactor: 1	Configs: segment.bytes=1073741824
	Topic: storage	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
----

We are going to create an RGW user and a bucket, we will use the user
credentials to configure notifications on the bucket

----
# radosgw-admin user create --uid='user1' --display-name='First User' --access-key='S3user1' --secret-key='S3user1key'
# aws --endpoint http://ceph-node02:8080 s3 mb s3://demobucket --region default
----

On the RadosGW side of things we are going to use a python script written by
Shon Paz, that makes the configuration of topics in RGW versy simple, from the
`ceph-node01` can run

----
# podman run shonpaz123/notify --help
usage: notify.py [-h] -e ENDPOINT_URL -a ACCESS_KEY -s SECRET_KEY -b
                 BUCKET_NAME [-ke KAFKA_ENDPOINT] [-ae AMQP_ENDPOINT]
                 [-he HTTP_ENDPOINT] -t TOPIC [-f FILTER] [-o OPAQUE]
                 [-x EXCHANGE] [-n NOTIFICATION]
# podman run shonpaz123/notify -a S3user1 -s S3user1key -b demobucket -ke workstation.example.com:9092 -t storage -e http://ceph-mon02:8080
----

Check that the topic got created at the RGW/ceph level

----
# radosgw-admin topic list
{
    "topics": [
        {
            "topic": {
                "user": "",
                "name": "configuration_storage",
                "dest": {
                    "bucket_name": "",
                    "oid_prefix": "",
                    "push_endpoint": "kafka://workstation.example.com:9092",
                    "push_endpoint_args": "Attributes.entry.1.key=push-endpoint&Attributes.entry.1.value=kafka://workstation.example.com:9092&Attributes.entry.2.key=kafka-ack-level&Attributes.entry.2.value=broker&Version=2010-03-31&kafka-ack-level=broker&push-endpoint=kafka://workstation.example.com:9092",
                    "push_endpoint_topic": "storage",
                    "stored_secret": "false",
                    "persistent": "false"
                },
                "arn": "arn:aws:sns:default::storage",
                "opaqueData": ""
            },
            "subs": []
        },
        {
            "topic": {
                "user": "",
                "name": "storage",
                "dest": {
                    "bucket_name": "",
                    "oid_prefix": "",
                    "push_endpoint": "kafka://workstation.example.com:9092",
                    "push_endpoint_args": "Attributes.entry.1.key=push-endpoint&Attributes.entry.1.value=kafka://workstation.example.com:9092&Attributes.entry.2.key=kafka-ack-level&Attributes.entry.2.value=broker&Version=2010-03-31&kafka-ack-level=broker&push-endpoint=kafka://workstation.example.com:9092",
                    "push_endpoint_topic": "storage",
                    "stored_secret": "false",
                    "persistent": "false"
                },
                "arn": "arn:aws:sns:default::storage",
                "opaqueData": ""
            },
            "subs": []
        }
    ]
}
----

Now that the bucket notification for topic `storage` is in place for bucket
`demobucket`, let's run a consumer on the topic and check if we can see the
bucket notifications for the S3 actions that take place on the bucket, from the
`workstation`

----
/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server workstation:9092 --topic storage --from-beginning
----

Lets create and delete and object in our `demobucket`

----
# aws --endpoint http://ceph-node02:8080 s3 cp /etc/hosts s3://demobucket/host1 --region default
upload: ../../../etc/hosts to s3://demobucket/host1
# aws --endpoint http://ceph-node02:8080 s3 rm s3://demobucket/host1
delete: s3://demobucket/host1
----

If we check our consumer process we can see the notifications pop-up

----
#/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server workstation:9092 --topic storage --from-beginning

{"Records":[{"eventVersion":"2.2","eventSource":"ceph:s3","awsRegion":"default","eventTime":"2023-01-13T12:59:25.628370Z","eventName":"ObjectCreated:Put","userIdentity":{"principalId":"user1"},"requestParameters":{"sourceIPAddress":""},"responseElements":{"x-amz-request-id":"624eb1a9-ead9-40f2-a057-5c1ee984b480.34108.15857281513954931534","x-amz-id-2":"853c-default-default"},"s3":{"s3SchemaVersion":"1.0","configurationId":"configuration","bucket":{"name":"demobucket","ownerIdentity":{"principalId":"user1"},"arn":"arn:aws:s3:::demobucket","id":"624eb1a9-ead9-40f2-a057-5c1ee984b480.34117.1"},"object":{"key":"host1","size":1330,"eTag":"b7828f6b873e43d1bacec3670a9f4510","versionId":"","sequencer":"AD55C163D1943926","metadata":[{"key":"x-amz-content-sha256","val":"1ef29c6abb4b7bc3cc04fb804b1850aecf84dc87493330b66c31bef5209680f3"},{"key":"x-amz-date","val":"20230113T125925Z"}],"tags":[]}},"eventId":"1673614765.641307.b7828f6b873e43d1bacec3670a9f4510","opaqueData":""}]}
{"Records":[{"eventVersion":"2.2","eventSource":"ceph:s3","awsRegion":"default","eventTime":"2023-01-13T13:00:22.848461Z","eventName":"ObjectRemoved:Delete","userIdentity":{"principalId":"user1"},"requestParameters":{"sourceIPAddress":""},"responseElements":{"x-amz-request-id":"624eb1a9-ead9-40f2-a057-5c1ee984b480.34108.15831645961373230453","x-amz-id-2":"853c-default-default"},"s3":{"s3SchemaVersion":"1.0","configurationId":"configuration","bucket":{"name":"demobucket","ownerIdentity":{"principalId":"user1"},"arn":"arn:aws:s3:::demobucket","id":"624eb1a9-ead9-40f2-a057-5c1ee984b480.34117.1"},"object":{"key":"host1","size":1330,"eTag":"b7828f6b873e43d1bacec3670a9f4510","versionId":"","sequencer":"E655C163DA949232","metadata":[{"key":"x-amz-content-sha256","val":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},{"key":"x-amz-date","val":"20230113T130022Z"}],"tags":[]}},"eventId":"1673614822.848467.b7828f6b873e43d1bacec3670a9f4510","opaqueData":""}]}
----

