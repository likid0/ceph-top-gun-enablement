= Rados Gateway Introduction and Deployment

.Goals
* Introduction to Object Storage
* Introduction to RadosGW
* Hands-On. Deploy RGW with Cephadm
* Hands-On. Verify S3/RGW Access with S3 client
* Hands-On. S3 Access: Path Style vs Hosted Style

:numbered:

== Pre-Req

* To complete this section you need a full Ceph cluster Deployed. 

* [OPTIONAL] If you have deployed using the available automation in the lab and you have radosGW running you can delete the services with the following steps.

----
# ceph orch rm rgw.objectgw
# ceph config set mon mon_allow_pool_delete true
# for i in $(ceph osd lspools | grep -E  'default.rgw' | awk '{print $NF}') ; do ceph osd pool rm $i $i --yes-i-really-really-mean-it ; done
----

== Introducing Object Storage

* Object storage is a type of data storage that stores data as objects, with each object having a unique identifier and metadata associated with it. The objects are typically stored across a cluster of commodity servers, and are accessed through a RESTful API. Object storage is different from traditional file and block storage, which store data in a hierarchical file system or as blocks on a storage device.

* Object storage is highly scalable, meaning it can easily handle large amounts of data and accommodate growth as needed. It allows you to store, retrieve and delete large amounts of unstructured data. The data can be accessed from anywhere, at any time, by any device that supports the RESTful API.

* Object storage is also designed to be highly durable and fault-tolerant. It uses techniques such as data replication and erasure coding to ensure that data is stored redundantly and can be recovered in the event of a failure. This makes it suitable for use cases such as archiving, backup and disaster recovery.

* Object storage is also cost-effective, it uses commodity hardware, which is less expensive than specialized storage hardware used in other types of storage systems.

* Object storage systems usually have built-in features such as data versioning, data tiering, and data lifecycle management.

* Object storage can be used for a variety of use cases, including archiving, backup and disaster recovery, media and entertainment, and big data analytics.

== Introducing RadosGW
The RADOS Gateway also called the Object Gateway (RGW), is a service that provides access to
the Ceph cluster for clients using standard object storage APIs. The RADOS Gateway supports
both the Amazon S3 and OpenStack Swift APIs.

The core daemon, radosgw, is built on top of the librados library. The daemon provides a web
service interface, based on the Beast HTTP, WebSocket, and networking protocol library, as a
front-end to handle API requests.

The radosgw is a client to Ceph Storage that provides object access to other client
applications. Client applications use standard APIs to communicate with the RADOS Gateway, and
the RADOS Gateway uses librados module calls to communicate with the Ceph cluster.

The RGW is a separate service that externally connects to a Ceph cluster and provides object storage
access to its clients. In a production environment, it's recommended that you run more than
one instance of the RGW masked by a Load Balancer.

Upstream general RGW documentation https://docs.ceph.com/en/quincy/radosgw/index.html[Link]

image::rgw-lb.webp[RGW LoadBalancer]

== RadosGW service deployment with Cephadm

Ceph Object Gateway supports two interfaces:

* *S3-compatibility* provides object storage functionality with an interface compatible with a large subset of the Amazon S3 RESTful API.
* *Swift-compatibility* , which provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.

`cephadm` deploys RGW as a collection of daemons that manage a single-cluster deployment or a particular realm and zone in a multisite deployment.
Note that with `cephadm`, the RGW daemons are configured via the monitor configuration database instead of via a `ceph.conf` file or the command line. If that configuration is not already in place (usually in the client.rgw.<something> section), then the RGW daemons start up with default settings (for example, binding to port 80).

There are many ways to deploy the RADOS object gateway one of which is through
a single cephadm command that creates an object gateway across two random servers.

In this lab we are going to follow a step-by-step approach to better understand the deployment process.

First we will create a realm, a zone group, and a zone, and then specify a placement specification with the hostname when you deploy the RGW daemons.

image::gateway-realm.png[RGW Realm,740,580]

[IMPORTANT]
====
Due to the limited number of OSDs in the lab environment, the `mon_max_pg_per_osd` configuration setting is lower than required. When you create more than seven pools each of PGs and PGPs, with the pool size being 32, you must increase the value of `mon_max_pg_per_osd` from `256` to `512` to create the additional pools.
====

The Realm/Zonegroup/Zone Layout in our Lab:

image::single-ms.png[Lab RGW layout]

. Update the value of the `mon_max_pg_per_osd` configuration variable to `512`:
+
[source,sh]
----
#  ceph config set mon mon_max_pg_per_osd 512
----

. Create a realm:
+
[source,sh]
----
# radosgw-admin realm create --rgw-realm=multisite --default
----
+
.Sample Output
[source,json]
----
{
    "id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "name": "multisite",
    "current_period": "0ad144e7-a880-43ab-8a64-c9deaf581280",
    "epoch": 1
}
----

. Create a zone group:
+
[source,sh]
----
# radosgw-admin zonegroup create --rgw-zonegroup=multizg  --master --default
----
+
.Sample Output
[source,json]
----
{
    "id": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
    "name": "multizg",
    "api_name": "multizg",
    "is_master": "true",
    "endpoints": [],
    "hostnames": [],
    "hostnames_s3website": [],
    "master_zone": "",
    "zones": [],
    "placement_targets": [],
    "default_placement": "",
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "sync_policy": {
        "groups": []
    }
}
----

. Create a zone:
+
[source,sh]
----
# radosgw-admin zone create --rgw-zonegroup=multizg --rgw-zone=zone1 --master --default
----
+
.Sample Output
[source,json]
----
{
    "id": "9db08233-a099-4905-a77c-b8964995037b",
    "name": "zone1",
    "domain_root": "zone1.rgw.meta:root",
    "control_pool": "zone1.rgw.control",
    "gc_pool": "zone1.rgw.log:gc",
    "lc_pool": "zone1.rgw.log:lc",
    "log_pool": "zone1.rgw.log",
    "intent_log_pool": "zone1.rgw.log:intent",
    "usage_log_pool": "zone1.rgw.log:usage",
    "roles_pool": "zone1.rgw.meta:roles",
    "reshard_pool": "zone1.rgw.log:reshard",
    "user_keys_pool": "zone1.rgw.meta:users.keys",
    "user_email_pool": "zone1.rgw.meta:users.email",
    "user_swift_pool": "zone1.rgw.meta:users.swift",
    "user_uid_pool": "zone1.rgw.meta:users.uid",
    "otp_pool": "zone1.rgw.otp",
    "system_key": {
        "access_key": "",
        "secret_key": ""
    },
    "placement_pools": [
        {
            "key": "default-placement",
            "val": {
                "index_pool": "zone1.rgw.buckets.index",
                "storage_classes": {
                    "STANDARD": {
                        "data_pool": "zone1.rgw.buckets.data"
                    }
                },
                "data_extra_pool": "zone1.rgw.buckets.non-ec",
                "index_type": 0
            }
        }
    ],
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "notif_pool": "zone1.rgw.log:notif"
}
----

. Commit the changes:
+
[source,sh]
----
# radosgw-admin period update --rgw-realm=multisite --commit
----
+
.Sample Output
[source,json]
----
{
    "id": "5fb483c5-b3cd-4f4d-9788-556f89aa613e",
    "epoch": 1,
    "predecessor_uuid": "0ad144e7-a880-43ab-8a64-c9deaf581280",
    "sync_status": [],
    "period_map": {
        "id": "5fb483c5-b3cd-4f4d-9788-556f89aa613e",
        "zonegroups": [
            {
                "id": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
                "name": "default",
                "api_name": "default",
                "is_master": "true",
                "endpoints": [],
                "hostnames": [],
                "hostnames_s3website": [],
                "master_zone": "9db08233-a099-4905-a77c-b8964995037b",
                "zones": [
                    {
                        "id": "9db08233-a099-4905-a77c-b8964995037b",
                        "name": "zone1",
                        "endpoints": [],
                        "log_meta": "false",
                        "log_data": "false",
                        "bucket_index_max_shards": 11,
                        "read_only": "false",
                        "tier_type": "",
                        "sync_from_all": "true",
                        "sync_from": [],
                        "redirect_zone": ""
                    }
                ],
                "placement_targets": [
                    {
                        "name": "default-placement",
                        "tags": [],
                        "storage_classes": [
                            "STANDARD"
                        ]
                    }
                ],
                "default_placement": "default-placement",
                "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
                "sync_policy": {
                    "groups": []
                }
            }
        ],
        "short_zone_ids": [
            {
                "key": "9db08233-a099-4905-a77c-b8964995037b",
                "val": 299831308
            }
        ]
    },
    "master_zonegroup": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
    "master_zone": "9db08233-a099-4905-a77c-b8964995037b",
    "period_config": {
        "bucket_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        },
        "user_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        }
    },
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "realm_name": "multisite",
    "realm_epoch": 2
}
----

. Deploy the RGW daemons with the name `multi.zone1`:
+
[source,sh]
----
# ceph orch apply rgw multi.zone1 --realm=multisite --zone=zone1 --placement="1 proxy01" --port=8000
----
+
.Sample Output
[source,texinfo]
----
Scheduled multi.zone1 update...
----

[TIP]
====
Use the client.rgw.* section in the centralised configuration database to define parameters and characteristics for new RADOS Gateway daemons.
====

. Verify that the RGW service is available:
+
[source,sh]
----
# ceph orch ls
----
+
.Sample Output
[source,texinfo]
----
NAME                       PORTS  RUNNING  REFRESHED  AGE  PLACEMENT
alertmanager                          1/1  9m ago     4d   count:1
crash                                 4/4  9m ago     4d   *
grafana                               1/1  9m ago     4d   count:1
mds.fs_name                           2/2  9m ago     3d   count:2
mgr                                   2/2  9m ago     4d   count:2
mon                                   4/5  9m ago     4d   count:5
node-exporter                         4/4  9m ago     4d   *
osd.all-available-devices             3/7  9m ago     4d   *
prometheus                            1/1  9m ago     4d   count:1
multi.zone1                   ?:8080       1/1  5s ago     12s  proxy01.example.com;count:1
----

. Verify that the RGW process is available:
+
[source,sh]
----
# ceph orch ps | grep rgw
----
+
.Sample Output
[source,texinfo]
----
ceph orch ps | grep rgw
rgw.multi.zone1.proxy01.mhawfj   proxy01      *:8000       running (4m)     3m ago   3m    54.9M        -  16.2.8-85.el8cp  b2c997ff1898  4de70934f04e
----

NOTE: The Ceph orchestrator service names the daemons by using the format rgw.<realm>.<zone>.<host>.<random-string>

. Also, verify that the RGW daemons are running:
+
[source,sh]
----
[root@ceph-mon01 ~]# ceph -s
----
+
.Sample Output
[source,texinfo]
----
  cluster:
    id:     7d4ee168-d9b9-11eb-bc7e-2cc260754989
    health: HEALTH_OK
  services:
    mon: 3 daemons, quorum ceph-mon01.example.com,ceph-mon02,ceph-mon03 (age 36m)
    mgr: ceph-mon02.pxyuuu(active, since 4h), standbys: ceph-mon01.example.com.cntwzr
    mds: 1/1 daemons up, 1 standby
    osd: 3 osds: 3 up (since 37m), 3 in (since 4d)
    rgw: 1 daemons active (1 hosts, 1 zones)

  data:
    volumes: 1/1 healthy
    pools:   10 pools, 273 pgs
    objects: 384 objects, 14 MiB
    usage:   169 MiB used, 30 GiB / 30 GiB avail
    pgs:     273 active+clean
----



== Verify Connectivity to RADOS Gateway

. Verify that the RADOS Gateway container is bound to port 8080 on `proxy01`:
+
[source,sh]
-----
[root@proxy01 ~]# netstat -tulpn
-----
+
.Sample Output
[source,texinfo]
-----
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
:
tcp        0      0 0.0.0.0:8080              0.0.0.0:*               LISTEN      25250/radosgw
:
:
tcp6       0      0 :::80                   :::*                    LISTEN      25250/radosgw
-----

. Use cURL to connect to each RADOS Gateway and check for a response on `ceph-mon01`:
+
[source,sh]
-----
[root@ceph-mon01 ceph-ansible]# curl http://proxy01:8000
-----
+
.Sample Output
[source,xml]
-----
<?xml version="1.0" encoding="UTF-8"?><ListAllMyBucketsResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/"><Owner><ID>anonymous</ID><DisplayName></DisplayName></Owner><Buckets></Buckets></ListAllMyBucketsResult>
-----

== Create RADOS Gateway User Accounts

To access Red Hat Ceph Storage over object storage interfaces via Swift or S3, you must configure a Ceph RADOS Gateway component. In this section, you configure `proxy01` as a Ceph RADOS Gateway and then test S3 and Swift from `ceph-mon01`.

You begin by logging into `ceph-mon01` to create RADOS Gateway user accounts to be used by S3 to access Ceph Storage via an object storage S3 cli client .

. Log in to `ceph-mon01`.
. Create an RGW user for S3 access:
+
[source,sh]
-----
[root@ceph-mon01 ceph-ansible]# radosgw-admin user create --uid='user1' --display-name='First User' --access-key='S3user1' --secret-key='S3user1key'
-----
+
.Sample Output
[source,json]
-----
{
    "user_id": "user1",
    "display_name": "First User",
    "email": "",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [],
    "keys": [
        {
            "user": "user1",
            "access_key": "S3user1",
            "secret_key": "S3user1key"
        }
    ],
    "swift_keys": [],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "temp_url_keys": [],
    "type": "rgw"
}
-----
+
. View the user information again:
+
[source,sh]
-----
[root@ceph-mon01 ]# radosgw-admin user info --uid='user1'
-----
* The output produced is the same as provided by the previous command.
* The Ceph RGW instances are already configured and running.

== Accessing S3 Objects Using RADOS Gateway

The Amazon S3 API enables developers to manage object storage resources using an Amazon
S3 compatible interface. Applications implemented with the S3 API can inter-operate with other
S3-compatible object storage services, besides the RADOS Gateway, migrate storage from
other locations to your Ceph storage cluster. In a hybrid cloud environment, you can configure
your applications to use different authentication keys, regions, and vendor services to mix private
enterprise and public cloud resources and storage locations seamlessly using the same API.
The Amazon S3 interface defines the namespace in which objects are stored as a bucket. To
access and manage objects and buckets using the S3 API, applications use RADOS Gateway
users for authentication. Each user has an access key that identifies the user and a secret key that
authenticates the user.
There are object and metadata size limits to consider when using the Amazon S3 API:
• An object size is between a minimum of OB and a maximum of 5 TB.
• The maximum size is 5GB in a single upload operation.
• Upload objects larger than 100MB by using the multipart upload capability.
• The maximum metadata size is 16,000 bytes in a single HTTP request.

== Using Amazon S3 API Clients

image::S3.png[AWS S3]

There are many different S3 clients that you can use to interact with the S3
API.

* s3cmd
* https://github.com/bloomreach/s4cmd[s4cmd]
* https://github.com/peak/s5cmd[s5cmd]
* https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html[AWS
* CLI]

We will be using the AWS CLI during the lab; the nodes have the AWS CLI binary
available, you will just need to configure it; using the configure option, you
can create a new RGW user or use the previously created user, you will need the
Access and Secret key.

----
# aws configure
AWS Access Key ID [****************07DO]:
AWS Secret Access Key [****************QUH0]:
Default region name [Default]: multizg
----

Once configured, you need to use the --endpoint option and point it to your
configure RGW HTTP endpoint, for example: 

----
# aws --endpoint http://proxy01:8000 s3 mb s3://demobucket --region multizg
----

== S3 bucket access types

The S3 API currently supports two different bucket addressing models: path-style (old) and virtual-hosted style (new).


=== What’s the difference?

*In path-style URLs*, the s3 bucket name will be in the URL path, examples:

S3 endpoint URL: “https://s3.example.com/bucket-name/object_key"

If you notice that the S3 bucket name and object keys are always in the same subdomain, which in this case is s3.example.com

*In hosted-style URLs*, the bucket name will be included on the subdomain so we can have distinct DNS subdomains for the buckets, examples:

----
https://bucket-name.s3.example.com/object_key
----

Hosted-style URL's can help with DNS resolution, scaling, security, traffic management, and DDoS protection more challenging with this old centralised model than unique, virtual-hosted-style subdomains.

=== How to enable hosted-style URLs in RadosGW

By default, RGW will work in the path-style URL format; if we want to access a bucket using the hosted-style URLs, some minimal configuration is needed.

The first thing would be getting DNS resolution ready; we will need to get a
wildcard DNS entry in place, so any DNS query that asks for *.bucket.example.com points to
Our Load Balancer or RGW instance, in our lab, we are using dnsmasq for DNS resolution so we are
going to add a new line to the dnsmasq config to get the DNS bucket resolution
working.

[NOTE]
====
Certain applications only work with hosted-style bucket access
====

[TIP]
====
RGW prefers the first method(Path Style), because the second
method(hosted-style) requires added operations like domain certification and DNS wild cards.
====

In this example, IP 172.16.7.24 is for proxy01 where we have our RGW instance
running, we add it at the end of the `/etc/dnsmasq.conf` of the `workstation`
server and finally restart dnsmasq.

On the `workstation.example.com` node:
----
# echo "address=/.bucket.example.com/172.16.7.24" >> /etc/dnsmasq.conf
# systemctl restart dnsmasq
# ping bucket1.bucket.example.com
PING bucket1.bucket.example.com (172.16.7.24) 56(84) bytes of data.
64 bytes from proxy01 (172.16.7.24): icmp_seq=1 ttl=64 time=2.18 ms
----

Now that DNS resolution is working, we need to configure our RGW instance; we can
configure the hosted-style URL access in two ways:

- Add the cname.domain.com to the rgw_dns_name config parameter per RGW instance
- add cname.domain.com to the list of hostnames in your zonegroup configuration

Let's get the name of our RGW instance

----
# ceph orch ps | grep rgw
rgw.multi.zone1.proxy01.yrtaci  proxy01      *:8000       running (63m)      2m ago   63m    65.5M        -  16.2.8-85.el8cp  b2c997ff1898  323585d51d1e  
----

And use the name of the RGW instance adding the client.  configure our DNS bucket subdomain
----
# ceph config ls | grep rgw_dns_name
rgw_dns_name

# ceph config set client.rgw.multi.zone1.proxy01.yrtaci rgw_dns_name bucket.example.com
----

Just so it's evident that we are successfully using the hosted-style access, I'm
going to do the following steps:

Create a bucket called bucket2, for example

----
# aws --endpoint http://proxy01:8000 s3 mb s3://bucket2 --region multizg
make_bucket: bucket2
----

Upload an object

----
# aws --endpoint http://proxy01:8000 s3 cp /etc/hosts  s3://bucket2 --region multizg
upload: ../etc/hosts to s3://bucket2/hosts
----

Modify the object ACL to give it public-read access so that it can be accessed by an
anonymous user with curl

----
# aws --endpoint http://proxy01:8000  s3api put-object-acl --bucket bucket2 --key hosts --acl public-read
----

Now I can access the object using curl with the hosted-style access, the bucket
name is in the URL as a subdomain, and the object is accessed directly without
specifying the name of the bucket

----
# curl http://bucket2.bucket.example.com:8000/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
----

If I remove the rgw_dns_name configuration, we can see what happens

----
# ceph config rm client.rgw.multi.zone1.proxy01.fybord rgw_dns_name
# ceph orch  daemon restart rgw.multi.zone1.proxy01.fybord
Scheduled to restart rgw.multi.zone1.proxy01.fybord on host 'proxy01'
# curl http://bucket2.bucket.example.com:8000/hosts
<?xml version="1.0" encoding="UTF-8"?><Error><Code>NoSuchBucket</Code><BucketName>hosts</BucketName><RequestId>tx00000809c18c68dcf0c57-0063b30865-858d-zone1</RequestId><HostId>858d-zone1-multizg</HostId></Error>
----

It will only work with path style:
----
# curl http://bucket2.bucket.example.com:8000/bucket2/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
----


The second way and recommended way of enabling hosted-style access is configuring our DNS host cname at the zone group configuration level:


----
# radosgw-admin zonegroup get > zonegroup.json
# vi zonegroup.json
...
"hostnames": [ "bucket.example.com" ],
...
# radosgw-admin zonegroup set --infile zonegroup.json
{
    "id": "9ebd51aa-9e79-45c8-ab5d-d6b92f389c10",
    "name": "multizg",
    "api_name": "multizg",
    "is_master": "true",
    "endpoints": [],
    "hostnames": [
        "bucket.example.com"
    ],
    "hostnames_s3website": [],
    "master_zone": "4bdeb630-734e-4b9f-9a7f-d1157de83b12",
    "zones": [
        {
            "id": "4bdeb630-734e-4b9f-9a7f-d1157de83b12",
            "name": "zone1",
            "endpoints": [],
            "log_meta": "false",
            "log_data": "false",
            "bucket_index_max_shards": 11,
            "read_only": "false",
            "tier_type": "",
            "sync_from_all": "true",
            "sync_from": [],
            "redirect_zone": ""
        }
    ],
    "placement_targets": [
        {
            "name": "default-placement",
            "tags": [],
            "storage_classes": [
                "STANDARD"
            ]
        }
    ],
    "default_placement": "default-placement",
    "realm_id": "4b6578f1-778b-4a51-95b1-4f81efb548b8",
    "sync_policy": {
        "groups": []
    }
}
#  radosgw-admin period update --commit
----

We do the same test as before and check that we can access using the
hosted-style access

----
# curl http://bucket2.bucket.example.com:8000/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
----


