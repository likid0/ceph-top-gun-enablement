= Rados Gateway Introduction and Deployment

.Goals
* Introduction to Object Storage
* Introduction to RadosGW
* Hands-On. Deploy RGW with Cephadm
* Hands-On. Verify S3/RGW Access with S3 client

:numbered:


== Introducing Object Storage

Object storage stores data as discrete items, each individually called an object. Unlike files in a file
system, objects are not organized in a tree of directories and subdirectories. Instead, objects are
stored in a flat namespace. Each object is retrieved by using the object's unique object ID, also
known as an object key.

Applications do not use normal file-system operations to access object data. Instead, applications
access a REST API to send and receive objects. Red Hat Ceph Storage supports the two most
common object APIs, Amazon S3 (Simple Storage Service) and OpenStack Swift (OpenStack
Object Storage).

Amazon S3 calls the flat namespace for object storage a bucket while OpenStack Swift calls it
a container. Because a namespace is flat, neither buckets nor containers can be nested. Ceph
typically uses the term bucket, as does this lecture.
A single user account can be configured for access to multiple buckets on the same storage
cluster. Buckets can each have different access permissions and be used to store objects for
different use cases.

The advantage of object storage is that it is easy to use, expand, and scale. Because each object
has a unique ID, it can be stored or retrieved without the user knowing the object's location.
Without the directory hierarchy, relationships between objects are simplified.
Objects, similar to files, contain a binary data stream and can grow to arbitrarily large sizes.
Objects also contain metadata about the object data, and natively support extended metadata
information, typically in the form of key-value pairs. You can also create your own metadata keys
and store custom information in the object as key values.

== Introducing RadosGW
The RADOS Gateway, also called the Object Gateway (RGW), is a service that provides access to
the Ceph cluster for clients using standard object storage APIs. The RADOS Gateway supports
both the Amazon S3 and OpenStack Swift APIs.

The core daemon, radosgw, is built on top of the librados library. The daemon provides a web
service interface, based on the Beast HTTP, WebSocket, and networking protocol library, as a
front-end to handle API requests.

The radosgw is a client to Ceph Storage that provides object access to other client
applications. Client applications use standard APIs to communicate with the RADOS Gateway, and
the RADOS Gateway uses librados module calls to communicate with the Ceph cluster.

The RGW is a separate service that externally connects to a Ceph cluster and provides object storage
access to its clients. In a production environment, it's recommended that you run more than
one instance of the RGW, masked by a Load Balancer,

image::rgw-lb.webp[RGW LoadBalancer]

== RadosGW service deployment with Cephadm

Ceph Object Gateway supports two interfaces:

* _S3-compatibility_, which provides object storage functionality with an interface that is compatible with a large subset of the Amazon S3 RESTful API.
* _Swift-compatibility_, which provides object storage functionality with an interface that is compatible with a large subset of the OpenStack Swift API.

`cephadm` deploys RGW as a collection of daemons that manage a single-cluster deployment or a particular realm and zone in a multisite deployment.
Note that with `cephadm`, the RGW daemons are configured via the monitor configuration database instead of via a `ceph.conf` file or the command line. If that configuration is not already in place (usually in the client.rgw.<something> section), then the RGW daemons start up with default settings (for example, binding to port 80).

There are many ways to deploy the RADOS object gateway on of which is through a single command that creates an object gateway across two random servers. You use a step-by-step method to gain a better understanding of the deployment process.

In this section, you create a realm, a zone group, and a zone, and then specify a placement specification with the host name when you deploy the RGW daemons.

image::gateway-realm.png[RGW Realm,740,580]

Due to the limited number of OSDs in the lab environment, the `mon_max_pg_per_osd` configuration setting is lower than required. When you create more than seven pools each of PGs and PGPs, with the pool size being 32, then you must increase the value of `mon_max_pg_per_osd` from `256` to `512` in order to create the additional pools.

. Update the value of the `mon_max_pg_per_osd` configuration variable to `512`:
+
[source,sh]
----
#  ceph config set mon mon_max_pg_per_osd 512
----

. Create a realm:
+
[source,sh]
----
# radosgw-admin realm create --rgw-realm=multisite --default
----
+
.Sample Output
[source,json]
----
{
    "id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "name": "multisite",
    "current_period": "0ad144e7-a880-43ab-8a64-c9deaf581280",
    "epoch": 1
}
----

. Create a zone group:
+
[source,sh]
----
# radosgw-admin zonegroup create --rgw-zonegroup=multizg  --master --default
----
+
.Sample Output
[source,json]
----
{
    "id": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
    "name": "multizg",
    "api_name": "multizg",
    "is_master": "true",
    "endpoints": [],
    "hostnames": [],
    "hostnames_s3website": [],
    "master_zone": "",
    "zones": [],
    "placement_targets": [],
    "default_placement": "",
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "sync_policy": {
        "groups": []
    }
}
----

. Create a zone:
+
[source,sh]
----
# radosgw-admin zone create --rgw-zonegroup=multizg --rgw-zone=zone1 --master --default
----
+
.Sample Output
[source,json]
----
{
    "id": "9db08233-a099-4905-a77c-b8964995037b",
    "name": "zone1",
    "domain_root": "zone1.rgw.meta:root",
    "control_pool": "zone1.rgw.control",
    "gc_pool": "zone1.rgw.log:gc",
    "lc_pool": "zone1.rgw.log:lc",
    "log_pool": "zone1.rgw.log",
    "intent_log_pool": "zone1.rgw.log:intent",
    "usage_log_pool": "zone1.rgw.log:usage",
    "roles_pool": "zone1.rgw.meta:roles",
    "reshard_pool": "zone1.rgw.log:reshard",
    "user_keys_pool": "zone1.rgw.meta:users.keys",
    "user_email_pool": "zone1.rgw.meta:users.email",
    "user_swift_pool": "zone1.rgw.meta:users.swift",
    "user_uid_pool": "zone1.rgw.meta:users.uid",
    "otp_pool": "zone1.rgw.otp",
    "system_key": {
        "access_key": "",
        "secret_key": ""
    },
    "placement_pools": [
        {
            "key": "default-placement",
            "val": {
                "index_pool": "zone1.rgw.buckets.index",
                "storage_classes": {
                    "STANDARD": {
                        "data_pool": "zone1.rgw.buckets.data"
                    }
                },
                "data_extra_pool": "zone1.rgw.buckets.non-ec",
                "index_type": 0
            }
        }
    ],
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "notif_pool": "zone1.rgw.log:notif"
}
----

. Commit the changes:
+
[source,sh]
----
# radosgw-admin period update --rgw-realm=multisite --commit
----
+
.Sample Output
[source,json]
----
{
    "id": "5fb483c5-b3cd-4f4d-9788-556f89aa613e",
    "epoch": 1,
    "predecessor_uuid": "0ad144e7-a880-43ab-8a64-c9deaf581280",
    "sync_status": [],
    "period_map": {
        "id": "5fb483c5-b3cd-4f4d-9788-556f89aa613e",
        "zonegroups": [
            {
                "id": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
                "name": "default",
                "api_name": "default",
                "is_master": "true",
                "endpoints": [],
                "hostnames": [],
                "hostnames_s3website": [],
                "master_zone": "9db08233-a099-4905-a77c-b8964995037b",
                "zones": [
                    {
                        "id": "9db08233-a099-4905-a77c-b8964995037b",
                        "name": "zone1",
                        "endpoints": [],
                        "log_meta": "false",
                        "log_data": "false",
                        "bucket_index_max_shards": 11,
                        "read_only": "false",
                        "tier_type": "",
                        "sync_from_all": "true",
                        "sync_from": [],
                        "redirect_zone": ""
                    }
                ],
                "placement_targets": [
                    {
                        "name": "default-placement",
                        "tags": [],
                        "storage_classes": [
                            "STANDARD"
                        ]
                    }
                ],
                "default_placement": "default-placement",
                "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
                "sync_policy": {
                    "groups": []
                }
            }
        ],
        "short_zone_ids": [
            {
                "key": "9db08233-a099-4905-a77c-b8964995037b",
                "val": 299831308
            }
        ]
    },
    "master_zonegroup": "2e41dde9-80f4-4ec8-a099-ec0e8a60938d",
    "master_zone": "9db08233-a099-4905-a77c-b8964995037b",
    "period_config": {
        "bucket_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        },
        "user_quota": {
            "enabled": false,
            "check_on_raw": false,
            "max_size": -1,
            "max_size_kb": 0,
            "max_objects": -1
        }
    },
    "realm_id": "ce31cd75-37c4-4b10-91db-1cda1ca12d95",
    "realm_name": "multisite",
    "realm_epoch": 2
}
----

. Deploy the RGW daemons with the name `multi.zone1`:
+
[source,sh]
----
# ceph orch apply rgw multi.zone1 --realm=multisite --zone=zone1 --placement="1 proxy01" --port=8000
----
+
.Sample Output
[source,texinfo]
----
Scheduled multi.zone1 update...
----

[TIP]
====
Use the client.rgw.* section in the centralized configuration database to define parameters and characteristics for new RADOS Gateway daemons.
====

. Verify that the RGW service is available:
+
[source,sh]
----
# ceph orch ls
----
+
.Sample Output
[source,texinfo]
----
NAME                       PORTS  RUNNING  REFRESHED  AGE  PLACEMENT
alertmanager                          1/1  9m ago     4d   count:1
crash                                 4/4  9m ago     4d   *
grafana                               1/1  9m ago     4d   count:1
mds.fs_name                           2/2  9m ago     3d   count:2
mgr                                   2/2  9m ago     4d   count:2
mon                                   4/5  9m ago     4d   count:5
node-exporter                         4/4  9m ago     4d   *
osd.all-available-devices             3/7  9m ago     4d   *
prometheus                            1/1  9m ago     4d   count:1
multi.zone1                   ?:8080       1/1  5s ago     12s  proxy01.example.com;count:1
----

. Verify that the RGW process is available:
+
[source,sh]
----
# ceph orch ps | grep rgw
----
+
.Sample Output
[source,texinfo]
----
ceph orch ps | grep rgw
rgw.multi.zone1.proxy01.mhawfj   proxy01      *:8000       running (4m)     3m ago   3m    54.9M        -  16.2.8-85.el8cp  b2c997ff1898  4de70934f04e
----

NOTE: The Ceph orchestrator service names the daemons by using the format rgw.<realm>.<zone>.<host>.<random-string>

. Also verify that the RGW daemons are running:
+
[source,sh]
----
[root@ceph-mon01 ~]# ceph -s
----
+
.Sample Output
[source,texinfo]
----
  cluster:
    id:     7d4ee168-d9b9-11eb-bc7e-2cc260754989
    health: HEALTH_OK
  services:
    mon: 3 daemons, quorum ceph-mon01.example.com,ceph-mon02,ceph-mon03 (age 36m)
    mgr: ceph-mon02.pxyuuu(active, since 4h), standbys: ceph-mon01.example.com.cntwzr
    mds: 1/1 daemons up, 1 standby
    osd: 3 osds: 3 up (since 37m), 3 in (since 4d)
    rgw: 1 daemons active (1 hosts, 1 zones)

  data:
    volumes: 1/1 healthy
    pools:   10 pools, 273 pgs
    objects: 384 objects, 14 MiB
    usage:   169 MiB used, 30 GiB / 30 GiB avail
    pgs:     273 active+clean
----



== Verify Connectivity to RADOS Gateway

. Verify that the RADOS Gateway container is bound to port 8080 on `proxy01`:
+
[source,sh]
-----
[root@proxy01 ~]# netstat -tulpn
-----
+
.Sample Output
[source,texinfo]
-----
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
:
tcp        0      0 0.0.0.0:8080              0.0.0.0:*               LISTEN      25250/radosgw
:
:
tcp6       0      0 :::80                   :::*                    LISTEN      25250/radosgw
-----

. Use cURL to connect to each RADOS Gateway and check for a response on `ceph-mon01`:
+
[source,sh]
-----
[root@ceph-mon01 ceph-ansible]# curl http://proxy01:8000
-----
+
.Sample Output
[source,xml]
-----
<?xml version="1.0" encoding="UTF-8"?><ListAllMyBucketsResult xmlns="http://s3.amazonaws.com/doc/2006-03-01/"><Owner><ID>anonymous</ID><DisplayName></DisplayName></Owner><Buckets></Buckets></ListAllMyBucketsResult>
-----

== Create RADOS Gateway User Accounts

To access Red Hat Ceph Storage over object storage interfaces--that is, via Swift or S3--you must configure a Ceph RADOS Gateway component. In this section, you configure `proxy01` as a Ceph RADOS Gateway and then test S3 and Swift from `ceph-mon01` or from `workstation`.

You begin by logging into `ceph-mon01` to create RADOS Gateway user accounts to be used by S3 and Swift APIs to access Red Hat Ceph Storage via an object storage interface.

. Log in to `ceph-mon01`.
. Create an RGW user for S3 access:
+
[source,sh]
-----
[root@ceph-mon01 ceph-ansible]# radosgw-admin user create --uid='user1' --display-name='First User' --access-key='S3user1' --secret-key='S3user1key'
-----
+
.Sample Output
[source,json]
-----
{
    "user_id": "user1",
    "display_name": "First User",
    "email": "",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [],
    "keys": [
        {
            "user": "user1",
            "access_key": "S3user1",
            "secret_key": "S3user1key"
        }
    ],
    "swift_keys": [],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "temp_url_keys": [],
    "type": "rgw"
}
-----
+
. View the user information again:
+
[source,sh]
-----
[root@ceph-mon01 ]# radosgw-admin user info --uid='user1'
-----
* The output produced is the same as provided by the previous command.
* The Ceph RGW instances are already configured and running.

== Accessing S3 Objects Using RADOS Gateway

The Amazon S3 API enables developers to manage object storage resources using an Amazon
S3 compatible interface. Applications implemented with the S3 API can inter-operate with other
S3-compatible object storage services besides the RADOS Gateway, and migrate storage from
other locations to your Ceph storage cluster. In a hybrid cloud environment, you can configure
your applications to use different authentication keys, regions, and vendor services to mix private
enterprise and public cloud resources and storage locations seamlessly using the same API.
The Amazon S3 interface defines the namespace in which objects are stored as a bucket. To
access and manage objects and buckets using the S3 API, applications use RADOS Gateway
users for authentication. Each user has an access key that identifies the user and a secret key that
authenticates the user.
There are object and metadata size limits to consider when using the Amazon S3 API:
• An object size is between a minimum of OB and a maximum of 5 TB.
• The maximum size is 5GB in a single upload operation.
• Upload objects larger than 100MB by using the multipart upload capability.
• The maximum metadata size is 16,000 bytes in a single HTTP request.

== Using Amazon S3 API Clients

image::S3.png[AWS S3]

There are many different S3 clients that you can use to interact with the S3
API.

* s3cmd
* https://github.com/bloomreach/s4cmd[s4cmd]
* https://github.com/peak/s5cmd[s5cmd]
* AWS CLI

We will be using the AWS CLI during the lab, the nodes have the AWS CLI binary
available you will just need to configure it, using the configure option, you
can create a new RGW user or use the previous created user, you will need the
Access and Secret key.

----
# aws configure
AWS Access Key ID [****************07DO]:
AWS Secret Access Key [****************QUH0]:
Default region name [Default]:
----

Once configured you need to use the --endpoint option and point it to your
configure RGW http endpoint, for example: 

----
[ceph: root@node /]# aws --endpoint http://ceph-node01:8080 s3 mb s3://demobucket
----

== S3 bucket access types

The S3 API currently supports two different bucket addressing models: path-style (old) and virtual-hosted style (new).


=== What’s the difference?

*In path-style URLs*, the s3 bucket name will be in the URL path, examples:

S3 endpoint URL: “https://s3.example.com/bucket-name/object_key"

If you notice that the S3 buckets name and objects keys always in the same subdomain which in this case s3.example.com

*In hosted-style URLs*, the bucket name will be included on the subdomain so we can have distinct DNS subdomains for the buckets, examples:

https://bucket-name.s3.example.com/object_key

Hosted style URL's can help with DNS resolution, scaling, security, traffic management, and DDoS protection more challenging with this old centralized model than unique, virtual-hosted style subdomains.

=== How to enable hosted-style URLs in RadosGW

By default RGW will work in the path-style URLs format, if we want to access a bucket using the hosted-style URLs some small configuration options are needed.

The first thing would be getting DNS resolution ready, we will need to get a
wildcard in place so any dns query that asks for *.bucket.example.com points to
our RGW instance, in our lab we are using dnsmasq for DNS resoultion so we are
going to add a new line to the dnsmasq config, to get the DNS bucket resolution
working.

[NOTE]
====
There are certain applications that only work with hosted-style bucket access
====

[TIP]
====
RGW prefers the first method(Path Style), because the second
method(hosted-style) requires added operations like domain certification and DNS wild cards.
====

In this example IP 172.16.7.24 is for proxy01 were we have our RGW instance
running:

----
# echo "address=/.bucket.example.com/172.16.7.24" >> /etc/dnsmasq.conf
# systemctl restart dnsmasq
# ping bucket1.bucket.example.com
PING bucket1.bucket.example.com (172.16.7.24) 56(84) bytes of data.
64 bytes from proxy01 (172.16.7.24): icmp_seq=1 ttl=64 time=2.18 ms
----

Now that DNS resoution is working we need to configure our RGW instance, we can
configure the hosted-style url access in two ways:

- Add the cname.domain.com to the rgw_dns_name config parameter per RGW instance
- add cname.domain.com to the list of hostnames in your zonegroup configuration

Lets get the name of our RGW instance

----
# ceph orch ps | grep rgw
rgw.multi.zone1.proxy01.yrtaci  proxy01      *:8000       running (63m)      2m ago   63m    65.5M        -  16.2.8-85.el8cp  b2c997ff1898  323585d51d1e  
----

And use the name of the RGW instance adding client.  configure our dns bucket subdomain
----
# ceph config ls | grep rgw_dns_name
rgw_dns_name

# ceph config set client.rgw.multi.zone1.proxy01.yrtaci rgw_dns_name bucket.example.com
----

Just so it's obivious that we are sucesfully using the hosted-style access, I'm
going to do the following steps:

Create a bucket called bucket2 for example

----
# aws --endpoint http://proxy01:8000 s3 mb s3://bucket2 --region multizg
make_bucket: bucket2
----

Upload an object

----
# aws --endpoint http://proxy01:8000 s3 cp /etc/hosts  s3://bucket2 --region multizg
upload: ../etc/hosts to s3://bucket2/hosts
----

Modify the object ACL to give it public-read access, so it can be access by an
anonymous user with curl

----
# aws --endpoint http://proxy01:8000  s3api put-object-acl --bucket bucket2 --key hosts --acl public-read
----

Now I can access the object using curl with the hosted-style access, the bucket
name is in the URL as a subdomain, and the object is access directly without
specifying the name of the bucket

----
# curl http://bucket2.bucket.example.com:8000/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
----

If I remove the rgw_dns_name configuration we can see what happens

----
# ceph config rm client.rgw.multi.zone1.proxy01.fybord rgw_dns_name
# ceph orch  daemon restart rgw.multi.zone1.proxy01.fybord
Scheduled to restart rgw.multi.zone1.proxy01.fybord on host 'proxy01'
# curl http://bucket2.bucket.example.com:8000/hosts
<?xml version="1.0" encoding="UTF-8"?><Error><Code>NoSuchBucket</Code><BucketName>hosts</BucketName><RequestId>tx00000809c18c68dcf0c57-0063b30865-858d-zone1</RequestId><HostId>858d-zone1-multizg</HostId></Error>
----

It will only work with path-style:
----
# curl http://bucket2.bucket.example.com:8000/bucket2/hosts
----


The second way and the recomended way of enabling hosted-style access is
configuring our dns host cname at zonegroup configuration level:


----
# radosgw-admin zonegroup get > zonegroup.json
# vi zonegroup.json
...
"hostnames": [ "bucket.example.com" ],
...
# radosgw-admin zonegroup set --infile zonegroup.json
{
    "id": "9ebd51aa-9e79-45c8-ab5d-d6b92f389c10",
    "name": "multizg",
    "api_name": "multizg",
    "is_master": "true",
    "endpoints": [],
    "hostnames": [
        "bucket.example.com"
    ],
    "hostnames_s3website": [],
    "master_zone": "4bdeb630-734e-4b9f-9a7f-d1157de83b12",
    "zones": [
        {
            "id": "4bdeb630-734e-4b9f-9a7f-d1157de83b12",
            "name": "zone1",
            "endpoints": [],
            "log_meta": "false",
            "log_data": "false",
            "bucket_index_max_shards": 11,
            "read_only": "false",
            "tier_type": "",
            "sync_from_all": "true",
            "sync_from": [],
            "redirect_zone": ""
        }
    ],
    "placement_targets": [
        {
            "name": "default-placement",
            "tags": [],
            "storage_classes": [
                "STANDARD"
            ]
        }
    ],
    "default_placement": "default-placement",
    "realm_id": "4b6578f1-778b-4a51-95b1-4f81efb548b8",
    "sync_policy": {
        "groups": []
    }
}
#  radosgw-admin period update --commit
----

We do the same test as before, and check that we can access using the
hosted-style access

----
# curl http://bucket2.bucket.example.com:8000/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
----
